import torch
import torch.nn as nn
from torchvision import transforms, models
from PIL import Image, ImageDraw, ImageFont
import os
import json
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from collections import defaultdict
import seaborn as sns



def setup_chinese_font():
    """è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ"""
    try:

        plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        print("âœ… ä¸­æ–‡å­—ä½“è®¾ç½®æˆåŠŸ")
    except:
        print("âš ï¸ ä¸­æ–‡å­—ä½“è®¾ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“")


class THOCRSystem:
    """å®Œæ•´çš„THOCRè¥¿å¤æ–‡è¯†åˆ«ç³»ç»Ÿ"""

    def __init__(self, model_dir='.'):
        self.device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
        self.model_dir = model_dir


        self.transform = transforms.Compose([
            transforms.Resize(100),
            transforms.CenterCrop(100),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])


        self.structure_classes = ['enclosed', 'horizontal', 'single', 'vertical']
        self.recognition_classes = {
                        'S': [
                'U+178A8',
                'U+17E15',
                'U+17E6D',
                'U+17F03',
                'U+17F86',
                'U+180D9',
                'U+181E5',
                'U+181F0',
                'U+1821A',
                'U+1824B',
                'U+1825D',
                'U+1825F',
                'U+1828F',
                'U+182DD',
                'U+18322',
                'U+18350',
                'U+1835D',
                'U+185E4',
                'U+185EA',
                'U+1866C',
            ],
            'V': [
                'U+17006',
                'U+17016',
                'U+1701F',
                'U+17100',
                'U+17108',
                'U+17109',
                'U+17116',
                'U+1742E',
                'U+17431',
                'U+17460',
                'U+17467',
                'U+1748C',
                'U+174C1',
                'U+174EB',
                'U+17552',
                'U+17564',
                'U+17572',
                'U+17683',
                'U+17684',
                'U+1768B',
                'U+1768C',
                'U+1768F',
                'U+176DC',
                'U+1771A',
                'U+17C86',
                'U+17CBA',
                'U+17D33',
                'U+17D35',
                'U+17D3F',
                'U+17D40',
                'U+17D49',
                'U+17D4A',
                'U+17D54',
                'U+17D55',
                'U+17D65',
                'U+17DA0',
                'U+17DA7',
                'U+17DB2',
                'U+17DB4',
                'U+17DB7',
                'U+17DB9',
                'U+18191',
                'U+1848A',
                'U+18497',
                'U+18527',
                'U+18797',
                'U+187BC',
                'U+187C0',
                'U+187C5',
                'U+187E0',
            ],
            'H': [
                'U+17030',
                'U+1712C',
                'U+1726D',
                'U+1732F',
                'U+17335',
                'U+17339',
                'U+1733E',
                'U+1734F',
                'U+17376',
                'U+17381',
                'U+173AC',
                'U+1757C',
                'U+17591',
                'U+1760B',
                'U+1760C',
                'U+17619',
                'U+1764B',
                'U+1764F',
                'U+178B3',
                'U+178CA',
                'U+17B7D',
                'U+17BE3',
                'U+17D7F',
                'U+17D8E',
                'U+17DDD',
                'U+17DF7',
                'U+17E16',
                'U+17E5D',
                'U+17E9B',
                'U+17F24',
                'U+17FDD',
                'U+1804C',
                'U+180BB',
                'U+180BE',
                'U+1812F',
                'U+18133',
                'U+18159',
                'U+18167',
                'U+181AD',
                'U+181BE',
                'U+1826B',
                'U+1839B',
                'U+1845B',
                'U+18474',
                'U+18517',
                'U+185FD',
                'U+18698',
                'U+186BC',
                'U+186E3',
                'U+187EE',
            ],
            'E': [
                'U+1711D',
                'U+171C5',
                'U+171CC',
                'U+17407',
                'U+1740A',
                'U+1741E',
                'U+17422',
                'U+17424',
                'U+17426',
                'U+17AF1',
                'U+17AF2',
                'U+17AF6',
                'U+17AF8',
                'U+17AF9',
                'U+17AFA',
                'U+17AFB',
                'U+17AFC',
                'U+17AFD',
                'U+17AFE',
                'U+17B01',
                'U+17B02',
                'U+17B03',
                'U+17B04',
                'U+17B05',
                'U+17B07',
                'U+17B08',
                'U+17B0A',
                'U+17B36',
                'U+17B64',
                'U+17B66',
                'U+17B9A',
                'U+17B9C',
                'U+17B9E',
                'U+17B9F',
                'U+17BA0',
                'U+17BA8',
                'U+17BA9',
                'U+17BB2',
                'U+17BB3',
                'U+17BB9',
                'U+17BC2',
                'U+17DE2',
                'U+17E1F',
                'U+1817E',
                'U+182C6',
                'U+1860B',
                'U+1860C',
                'U+1860F',
                'U+186C3',
                'U+1871B',
            ],
        }

        # åŠ è½½æ¨¡å‹
        self.structure_classifier = self.load_structure_classifier()
        self.recognizers = {
            'S': self.load_recognizer('S'),
            'V': self.load_recognizer('V'),
            'H': self.load_recognizer('H'),
            'E': self.load_recognizer('E')
        }

    def load_structure_classifier(self):
        """åŠ è½½ç»“æ„åˆ†ç±»å™¨"""
        model = models.resnet18()
        model.fc = nn.Linear(model.fc.in_features, 4)
        model.load_state_dict(torch.load('best_tangut_structure_classifier_balanced.pth',
                                         map_location=self.device))
        model.eval()
        return model.to(self.device)

    def load_recognizer(self, structure_type):
        """åŠ è½½æ–‡å­—è¯†åˆ«å™¨"""
        model = models.resnet18()
        num_classes = len(self.recognition_classes[structure_type])
        model.fc = nn.Linear(model.fc.in_features, num_classes)
        model.load_state_dict(torch.load(f'tangut_recognizer_{structure_type}_v2.pth',
                                         map_location=self.device))
        model.eval()
        return model.to(self.device)

    def predict(self, image_path):
        """å®Œæ•´è¯†åˆ«æµç¨‹"""
        image = Image.open(image_path).convert('RGB')
        input_tensor = self.transform(image).unsqueeze(0).to(self.device)

        # ç»“æ„åˆ†ç±»
        with torch.no_grad():
            structure_output = self.structure_classifier(input_tensor)
            structure_pred = torch.argmax(structure_output, 1).item()
            structure_label = self.structure_classes[structure_pred]
            structure_map = {'enclosed': 'E', 'horizontal': 'H',
                             'single': 'S', 'vertical': 'V'}
            structure_code = structure_map[structure_label]

        # æ–‡å­—è¯†åˆ«
        recognizer = self.recognizers[structure_code]
        with torch.no_grad():
            char_output = recognizer(input_tensor)
            char_pred = torch.argmax(char_output, 1).item()
            char_label = self.recognition_classes[structure_code][char_pred]

        return {
            'structure': structure_label,
            'character': char_label,
            'confidence': {
                'structure': torch.softmax(structure_output, 1)[0][structure_pred].item(),
                'character': torch.softmax(char_output, 1)[0][char_pred].item()
            }
        }


def test_integrated_system():
    """æµ‹è¯•é›†æˆç³»ç»Ÿå¹¶ç”Ÿæˆè®ºæ–‡ç”¨å›¾è¡¨"""

    print("å¼€å§‹é›†æˆç³»ç»Ÿæµ‹è¯•...")
    thocr = THOCRSystem()

    test_dir = 'testDatabase'
    results = []
    confusion_data = []

    # éå†æµ‹è¯•æ•°æ®é›†
    for filename in os.listdir(test_dir):
        if filename.endswith(('.png', '.jpg', '.jpeg')):
            filepath = os.path.join(test_dir, filename)

            # ä»æ–‡ä»¶åè§£æçœŸå®æ ‡ç­¾
            basename = os.path.splitext(filename)[0]
            parts = basename.split('+')
            if len(parts) >= 2:
                true_char = 'U+' + parts[1][:5]
                true_structure = parts[1][-1]
                structure_map = {'S': 'single', 'V': 'vertical', 'H': 'horizontal', 'E': 'enclosed'}
                true_structure_label = structure_map.get(true_structure, 'unknown')
            else:
                continue

            # è¿›è¡Œé¢„æµ‹
            try:
                result = thocr.predict(filepath)

                # è®°å½•ç»“æœ
                test_result = {
                    'filename': filename,
                    'true_char': true_char,
                    'true_structure': true_structure_label,
                    'pred_char': result['character'],
                    'pred_structure': result['structure'],
                    'char_confidence': result['confidence']['character'],
                    'structure_confidence': result['confidence']['structure'],
                    'char_correct': true_char == result['character'],
                    'structure_correct': true_structure_label == result['structure'],
                    'both_correct': (true_char == result['character']) and (true_structure_label == result['structure'])
                }
                results.append(test_result)

                # è®°å½•æ··æ·†çŸ©é˜µæ•°æ®
                confusion_data.append({
                    'true_structure': true_structure_label,
                    'pred_structure': result['structure'],
                    'true_char': true_char,
                    'pred_char': result['character']
                })

                status = "âœ…" if test_result['both_correct'] else "âŒ"
                print(f"{status} {filename}: ç»“æ„({true_structure_label}â†’{result['structure']}) "
                      f"å­—ç¬¦({true_char}â†’{result['character']}) "
                      f"ç½®ä¿¡åº¦: ç»“æ„{result['confidence']['structure']:.2%}, å­—ç¬¦{result['confidence']['character']:.2%}")

            except Exception as e:
                print(f"âŒ {filename}: è¯†åˆ«å¤±è´¥ - {e}")

    # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
    generate_test_report(results, confusion_data)

    # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
    generate_visualizations(results, confusion_data)

    # ç”Ÿæˆç¤ºä¾‹è¯†åˆ«ç»“æœå›¾
    generate_example_results(thocr, test_dir, results)


def generate_test_report(results, confusion_data):
    """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""

    print("\n" + "=" * 60)
    print("é›†æˆç³»ç»Ÿæµ‹è¯•æŠ¥å‘Š")
    print("=" * 60)

    df = pd.DataFrame(results)

    # åŸºç¡€ç»Ÿè®¡
    total_tests = len(results)
    structure_accuracy = df['structure_correct'].mean() * 100
    char_accuracy = df['char_correct'].mean() * 100
    both_accuracy = df['both_correct'].mean() * 100

    print(f"æµ‹è¯•æ ·æœ¬æ€»æ•°: {total_tests}")
    print(f"ç»“æ„åˆ†ç±»å‡†ç¡®ç‡: {structure_accuracy:.2f}%")
    print(f"æ–‡å­—è¯†åˆ«å‡†ç¡®ç‡: {char_accuracy:.2f}%")
    print(f"ç«¯åˆ°ç«¯å‡†ç¡®ç‡: {both_accuracy:.2f}%")


    print("\næŒ‰ç»“æ„ç±»å‹ç»Ÿè®¡:")
    structure_stats = df.groupby('true_structure').agg({
        'structure_correct': 'mean',
        'char_correct': 'mean',
        'both_correct': 'mean',
        'filename': 'count'
    }).round(4) * 100

    structure_stats.columns = ['ç»“æ„å‡†ç¡®ç‡%', 'æ–‡å­—å‡†ç¡®ç‡%', 'ç«¯åˆ°ç«¯å‡†ç¡®ç‡%', 'æ ·æœ¬æ•°']
    print(structure_stats)


    print(f"\nå¹³å‡ç½®ä¿¡åº¦:")
    print(f"  ç»“æ„åˆ†ç±»: {df['structure_confidence'].mean():.2%}")
    print(f"  æ–‡å­—è¯†åˆ«: {df['char_confidence'].mean():.2%}")


    df.to_csv('thocr_test_results.csv', index=False, encoding='utf-8-sig')
    print(f"\nè¯¦ç»†ç»“æœå·²ä¿å­˜è‡³: thocr_test_results.csv")


def generate_visualizations(results, confusion_data):
    """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""

    df = pd.DataFrame(results)
    confusion_df = pd.DataFrame(confusion_data)

    # è®¾ç½®ä¸­æ–‡å­—ä½“
    setup_chinese_font()

    # ä¿®å¤æ ·å¼é—®é¢˜
    try:
        plt.style.use('seaborn-v0_8')
    except:
        try:
            plt.style.use('seaborn')
        except:
            plt.style.use('default')

    fig, axes = plt.subplots(2, 2, figsize=(15, 12))

    # 1. å‡†ç¡®ç‡å¯¹æ¯”å›¾ - ä½¿ç”¨è‹±æ–‡é¿å…å­—ä½“é—®é¢˜
    accuracy_data = {
        'Structure\nClassification': df['structure_correct'].mean() * 100,
        'Character\nRecognition': df['char_correct'].mean() * 100,
        'End-to-End': df['both_correct'].mean() * 100
    }

    colors = ['#2E86AB', '#A23B72', '#F18F01']
    bars = axes[0, 0].bar(accuracy_data.keys(), accuracy_data.values(), color=colors)
    axes[0, 0].set_title('THOCR System Performance', fontsize=14, fontweight='bold')
    axes[0, 0].set_ylabel('Accuracy (%)')
    axes[0, 0].set_ylim(0, 105)

    # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼
    for bar, v in zip(bars, accuracy_data.values()):
        height = bar.get_height()
        axes[0, 0].text(bar.get_x() + bar.get_width() / 2., height + 1,
                        f'{v:.1f}%', ha='center', va='bottom', fontweight='bold', fontsize=11)

    # 2. ç»“æ„ç±»å‹æ€§èƒ½å¯¹æ¯” - ä½¿ç”¨è‹±æ–‡
    structure_performance = df.groupby('true_structure')['both_correct'].mean() * 100
    structure_names = {
        'enclosed': 'Enclosed',
        'horizontal': 'Horizontal',
        'single': 'Single',
        'vertical': 'Vertical'
    }
    structure_labels = [structure_names.get(s, s) for s in structure_performance.index]

    bars = axes[0, 1].bar(structure_labels, structure_performance.values, color='#2E86AB')
    axes[0, 1].set_title('Accuracy by Structure Type', fontsize=14, fontweight='bold')
    axes[0, 1].set_ylabel('Accuracy (%)')
    axes[0, 1].set_ylim(0, 105)

    for bar, v in zip(bars, structure_performance.values):
        height = bar.get_height()
        axes[0, 1].text(bar.get_x() + bar.get_width() / 2., height + 1,
                        f'{v:.1f}%', ha='center', va='bottom', fontweight='bold', fontsize=11)

    # 3. ç½®ä¿¡åº¦åˆ†å¸ƒ
    axes[1, 0].hist(df['structure_confidence'], bins=20, alpha=0.7,
                    label='Structure Classification', color='#2E86AB')
    axes[1, 0].hist(df['char_confidence'], bins=20, alpha=0.7,
                    label='Character Recognition', color='#A23B72')
    axes[1, 0].set_title('Confidence Distribution', fontsize=14, fontweight='bold')
    axes[1, 0].set_xlabel('Confidence')
    axes[1, 0].set_ylabel('Frequency')
    axes[1, 0].legend()

    # 4. ç»“æ„åˆ†ç±»æ··æ·†çŸ©é˜µ - ä½¿ç”¨è‹±æ–‡
    if len(confusion_df) > 0:
        # å°†æ ‡ç­¾è½¬æ¢ä¸ºè‹±æ–‡
        confusion_df_eng = confusion_df.copy()
        label_map = {
            'enclosed': 'Enclosed',
            'horizontal': 'Horizontal',
            'single': 'Single',
            'vertical': 'Vertical'
        }
        confusion_df_eng['true_structure'] = confusion_df_eng['true_structure'].map(label_map)
        confusion_df_eng['pred_structure'] = confusion_df_eng['pred_structure'].map(label_map)

        structure_confusion = pd.crosstab(
            confusion_df_eng['true_structure'],
            confusion_df_eng['pred_structure'],
            rownames=['True Structure'],
            colnames=['Predicted Structure']
        )
        sns.heatmap(structure_confusion, annot=True, fmt='d', cmap='Blues', ax=axes[1, 1])
        axes[1, 1].set_title('Structure Classification\nConfusion Matrix', fontsize=14, fontweight='bold')
    else:
        axes[1, 1].text(0.5, 0.5, 'No confusion matrix data',
                        ha='center', va='center', fontsize=12)
        axes[1, 1].set_title('Structure Classification\nConfusion Matrix', fontsize=14, fontweight='bold')

    plt.tight_layout()
    plt.savefig('thocr_performance_analysis.png', dpi=300, bbox_inches='tight',
                facecolor='white', edgecolor='none')
    plt.show()

    print(f" Performance analysis chart saved to: thocr_performance_analysis.png")


def generate_example_results(thocr, test_dir, results, num_examples=12):
    """ç”Ÿæˆç¤ºä¾‹è¯†åˆ«ç»“æœå›¾"""

    if len(results) == 0:
        print("No result data available for example generation")
        return

    # é€‰æ‹©ä¸€äº›æœ‰ä»£è¡¨æ€§çš„ä¾‹å­
    df = pd.DataFrame(results)
    correct_examples = df[df['both_correct'] == True].head(6)
    wrong_examples = df[df['both_correct'] == False].head(6)

    selected_examples = pd.concat([correct_examples, wrong_examples]).head(num_examples)

    # åˆ›å»ºç»“æœå›¾
    fig, axes = plt.subplots(3, 4, figsize=(16, 12))
    axes = axes.flatten()

    for idx, (_, example) in enumerate(selected_examples.iterrows()):
        if idx >= len(axes):
            break

        filepath = os.path.join(test_dir, example['filename'])
        try:
            image = Image.open(filepath)
            axes[idx].imshow(image)
        except Exception as e:
            axes[idx].text(0.5, 0.5, f'Image load failed\n{example["filename"]}',
                           ha='center', va='center', fontsize=10)

        axes[idx].axis('off')

        # è®¾ç½®æ ‡é¢˜é¢œè‰²ï¼šæ­£ç¡®ä¸ºç»¿è‰²ï¼Œé”™è¯¯ä¸ºçº¢è‰²
        color = 'green' if example['both_correct'] else 'red'

        # ä½¿ç”¨è‹±æ–‡æ ‡ç­¾é¿å…å­—ä½“é—®é¢˜
        structure_map = {
            'enclosed': 'E', 'horizontal': 'H', 'single': 'S', 'vertical': 'V'
        }

        title = (f"True: {example['true_char']}({structure_map[example['true_structure']]})\n"
                 f"Pred: {example['pred_char']}({structure_map[example['pred_structure']]})\n"
                 f"Conf: {example['char_confidence']:.1%}")

        axes[idx].set_title(title, color=color, fontsize=9, pad=6)

    # éšè—å¤šä½™çš„å­å›¾
    for idx in range(len(selected_examples), len(axes)):
        axes[idx].axis('off')

    plt.suptitle('THOCR Recognition Examples (Green: Correct, Red: Incorrect)',
                 fontsize=16, fontweight='bold', y=0.95)
    plt.tight_layout()
    plt.savefig('thocr_example_results.png', dpi=300, bbox_inches='tight',
                facecolor='white', edgecolor='none')
    plt.show()

    print(f"ğŸ–¼ï¸ Example results saved to: thocr_example_results.png")


if __name__ == "__main__":
    # åˆå§‹åŒ–ä¸­æ–‡å­—ä½“æ”¯æŒ
    setup_chinese_font()
    test_integrated_system()